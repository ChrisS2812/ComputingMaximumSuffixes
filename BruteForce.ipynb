{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tries to find an algorithm that finds the longest suffix of any given word with length N while using only M comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "import itertools\n",
    "import datetime \n",
    "import random\n",
    "import traceback\n",
    "import timeit\n",
    "import threading\n",
    "\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from anytree import Node, RenderTree, LevelOrderIter\n",
    "from anytree.exporter import DotExporter\n",
    "from anytree.importer import JsonImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5\n",
    "M=5\n",
    "DEBUG=True\n",
    "ONLY_HIGHEST_DEBUG=True\n",
    "NR_WORKERS = 1\n",
    "\n",
    "dir = \"N{}M{}\".format(N,M)\n",
    "Path(dir).mkdir(parents=True, exist_ok=True)\n",
    "checkpoint_dir = os.path.join(dir, 'checkpoint')\n",
    "Path(checkpoint_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute all possible pairs of indices that can be compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n"
     ]
    }
   ],
   "source": [
    "comp_pairs = []\n",
    "for i in range(N):\n",
    "    for j in range(i+1,N):\n",
    "        comp_pairs.append((i,j))\n",
    "print(comp_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duval's algorithm for finding the index of maximum suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_suffix_duval(word):\n",
    "    r = 0\n",
    "    s = 1\n",
    "    m = 1\n",
    "    n = len(word)\n",
    "    M = {}\n",
    "    M[1] = 1\n",
    "    while(s < n):\n",
    "        if word[s] < word[s-m]:\n",
    "            s = s+1\n",
    "            m = s-r\n",
    "            M[m] = m\n",
    "        elif word[s] == word[s-m]:\n",
    "            s = s+1\n",
    "            M[s-r] = m\n",
    "        else:\n",
    "            d = (s-r) % m\n",
    "            if (d > 0):\n",
    "                r = s-d\n",
    "                m = M[d]\n",
    "            else:\n",
    "                r = s\n",
    "                s +=1\n",
    "                m = 1\n",
    "    return(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create all possible words for a given N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_word_with_max_suffix():\n",
    "    \n",
    "    #List of all words\n",
    "    all_words = list(itertools.product(range(N), repeat=N))\n",
    "\n",
    "    #Reduce this to list of relevant words by defining two words as equivalent if all its pairwise comparisons have the same result\n",
    "    comp_result_2_word = {}\n",
    "    for word in all_words:\n",
    "        comparisons = \"\"\n",
    "        for i in range(N):\n",
    "            for j in range(i+1,N):\n",
    "                c1 = word[i]\n",
    "                c2 = word[j]\n",
    "                if c1 < c2:\n",
    "                    comparisons += \"<\"\n",
    "                elif c1 > c2:\n",
    "                    comparisons += \">\"\n",
    "                else:\n",
    "                    comparisons += \"=\"\n",
    "        if comparisons not in comp_result_2_word:\n",
    "            comp_result_2_word[comparisons] = word\n",
    "\n",
    "    rel_words = []\n",
    "\n",
    "    for entry in comp_result_2_word.values():\n",
    "        word = ''\n",
    "        for char in entry:\n",
    "            word += str(char)\n",
    "        rel_words.append(word)\n",
    "\n",
    "    # Create the correct maximum suffix index for each relevant word and save it together with word in tuple\n",
    "    words_with_max_suffix = []\n",
    "    for word in rel_words:\n",
    "        words_with_max_suffix.append((word, max_suffix_duval(word)))\n",
    "\n",
    "    return words_with_max_suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helping function that computes the path of of a given word in a given decision tree in the form:\n",
    "* (n_1,...,n_m) where n_i represents the id of the i'th node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_path_for_word(alg, word):    \n",
    "    current_index = 0\n",
    "    path = []\n",
    "    while(current_index < len(alg)):\n",
    "        path.append(current_index)\n",
    "        if is_leaf(current_index):\n",
    "            break\n",
    "        i1, i2 = alg[current_index].obj\n",
    "        c1 = word[i1]\n",
    "        c2 = word[i2]\n",
    "        if c1 < c2:\n",
    "            current_index = current_index * 3 + 1\n",
    "        elif c1 == c2:\n",
    "            current_index = current_index * 3 + 2\n",
    "        else:\n",
    "            current_index = current_index * 3 + 3\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helping function that computes (all) decision-tree-independent path representation on which a given index lies. A path is a string of the form\n",
    "* c_1r_1c_2_r_2...c_M\n",
    "\n",
    "where c_i represents a comparison and r_i the result of this comparison (\"<\", \"=\", or \">\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_path_repr_for_index(alg, index):\n",
    "    if is_leaf(index):\n",
    "        return compute_path_repr_for_index(alg, (index - 1) // 3)\n",
    "    if is_last_comp(index):\n",
    "        #start at lowest comparison node (the last node is not important for blacklisted paths)\n",
    "        repr = str(alg[index].obj)\n",
    "        while (index != 0):\n",
    "            mod = index % 3\n",
    "            if mod == 0:\n",
    "                repr = \">\" + repr\n",
    "            elif mod == 1:\n",
    "                repr = \"<\" + repr\n",
    "            else:\n",
    "                repr = \"=\" + repr\n",
    "            index = (index - 1) // 3\n",
    "            repr = str(alg[index].obj) + repr\n",
    "        return [repr]\n",
    "    else:\n",
    "        result = []\n",
    "        #Append paths for all children\n",
    "        result.extend(compute_path_repr_for_index(alg, index*3 + 1))\n",
    "        result.extend(compute_path_repr_for_index(alg, index*3 + 2))\n",
    "        result.extend(compute_path_repr_for_index(alg, index*3 + 3))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helping function that decides whether a node at a given index is a leaf or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_leaf(index):\n",
    "    if M < 1:\n",
    "        return True\n",
    "    \n",
    "    last_non_leaf_index = -1\n",
    "    for i in range(0, M):\n",
    "        last_non_leaf_index += 3**i\n",
    "    if index <= last_non_leaf_index:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helping function that decides whether a node at a given index represents the last comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_last_comp(index):\n",
    "    if M < 1:\n",
    "        return False\n",
    "    if M == 2:\n",
    "        if index == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    if is_leaf(index):\n",
    "        return False\n",
    "    \n",
    "    last_non_last_comp_index = -1\n",
    "    for i in range(0, M-1):\n",
    "        last_non_last_comp_index += 3**i\n",
    "    \n",
    "    if index > last_non_last_comp_index:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helping function that computes for a list of previously executed comparison and a new (current) comparison whether, after carrying out the new comparison, any other comparisons can be deduced transitively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transitive_dependencies(previous_comps, current_comp):\n",
    "    result = []\n",
    "    (cc1, cc2), cr = current_comp\n",
    "    for (pc1, pc2), pr in previous_comps:\n",
    "        if cc1 == pc1:\n",
    "            # (i,j) and (i,k)\n",
    "            if cr == '=' or pr == '=' or (cr == '<' and pr == '>') or (cr == '>' and pr == '<'):\n",
    "                result.append(tuple(sorted((cc2,pc2))))\n",
    "        elif cc2 == pc2:\n",
    "            # (i,j) and (k,j)\n",
    "            if cr == '=' or pr == '=' or (cr == '<' and pr == '>') or (cr == '>' and pr == '<'):\n",
    "                result.append(tuple(sorted((cc1,pc1))))\n",
    "        elif cc1 == pc2:\n",
    "            # (i,j) and (k,i):\n",
    "            if cr == '=' or pr == '=' or (cr == '<' and pr == '<') or (cr == '>' and pr == '>'):\n",
    "                result.append(tuple(sorted((cc2,pc1))))\n",
    "        elif cc2 == pc1:\n",
    "            # (i,j) and (j,k):\n",
    "            if cr == '=' or pr == '=' or (cr == '<' and pr == '<') or (cr == '>' and pr == '>'):\n",
    "                result.append(tuple(sorted((cc1,pc2))))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates a decision tree for M comparisons with given root value that fulfils the following rules:\n",
    "1. No path contains the same node value twice\n",
    "2. Every node must have at least two different successors\n",
    "3. Every height value must have at least two different states\n",
    "\n",
    "Define a tree structure inside a list, each representing a different height of the tree. Anytree helps us navigating the tree (i.e. finding children, parents etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_algorithm(root_value):\n",
    "    alg = []\n",
    "    current_index = 0\n",
    "    for i in range(M+1):\n",
    "        if i == 0:\n",
    "            #Root Node\n",
    "            root = Node(current_index, obj=root_value)\n",
    "            alg.append(root)\n",
    "            current_index += 1\n",
    "        elif i == M:\n",
    "            #Leaf Nodes\n",
    "            for j in range(3**M):\n",
    "                parent = alg[(current_index-1) // 3]\n",
    "                alg.append(Node(current_index, obj=\"\", parent=parent))\n",
    "                current_index +=1\n",
    "        else:\n",
    "            for j in range(3**i):\n",
    "                parent = alg[(current_index-1) // 3]\n",
    "                parent_index = current_index\n",
    "                parent_values = []\n",
    "                #Collect all values of (grand-)parents of the current node\n",
    "                while (parent_index != 0):\n",
    "                    parent_index = (parent_index-1) // 3\n",
    "                    parent_values.append(alg[parent_index].obj)\n",
    "                    \n",
    "                for pair in comp_pairs:\n",
    "                    if pair not in parent_values:\n",
    "                        alg.append(Node(current_index, obj=pair, parent=parent))\n",
    "                        current_index += 1\n",
    "                        break\n",
    "    return alg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helping function that saves current state of algorithm (i.e. the current tree) to a file from which it can be reloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_current_graph(root, interval, still_running):\n",
    "    while still_running.is_set():\n",
    "        i = 0\n",
    "        while True:\n",
    "            if not still_running.is_set() or i == interval // 60:\n",
    "                #save a last time\n",
    "                ts = str(datetime.datetime.now().timestamp() * 1000)\n",
    "                filename = \"{}_{}\".format(root.obj, ts)\n",
    "                final_path = os.path.join(checkpoint_dir, filename)\n",
    "                DotExporter(root, nodeattrfunc=lambda node: 'label=\"{}\"'.format(node.obj)).to_dotfile(\"{}.txt\".format(final_path))\n",
    "                return\n",
    "            elif i == interval / 60:\n",
    "                #time for a regular save\n",
    "                ts = str(datetime.datetime.now().timestamp() * 1000)\n",
    "                filename = \"{}_{}\".format(root.obj, ts)\n",
    "                final_path = os.path.join(checkpoint_dir, filename)\n",
    "                DotExporter(root, nodeattrfunc=lambda node: 'label=\"{}\"'.format(node.obj)).to_dotfile(\"{}.txt\".format(final_path))\n",
    "                break\n",
    "            else:\n",
    "                #Nothing to do here\n",
    "                time.sleep(5)    \n",
    "                # dirty solution for regularly checking for liveness\n",
    "                i += 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helping function that loads the state of an algorithm for the time of a given checkpoint if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alg_from_checkpoint(root_comp):\n",
    "    chkpnt_files = [f for f in listdir(checkpoint_dir) if isfile(join(checkpoint_dir, f)) \n",
    "                 and f.startswith(str(root_comp))]\n",
    "    \n",
    "    if not chkpnt_files:\n",
    "        return -1\n",
    "    \n",
    "    chkpnt_files.sort()\n",
    "    most_recent_checkpoint = chkpnt_files[-1]\n",
    "    \n",
    "    path_to_most_recent_checkpoint = os.path.join(checkpoint_dir, most_recent_checkpoint)\n",
    "    \n",
    "    with open (path_to_most_recent_checkpoint, 'r') as f:\n",
    "        root = JsonImporter().read(f)\n",
    "    \n",
    "    alg = [node for node in LevelOrderIter(root)]\n",
    "    \n",
    "    return alg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: describe\n",
    "def check_alg_for_root_comp(root_comp, words_with_max_suffix, comps):\n",
    "    alg = generate_algorithm(root_comp)\n",
    "    if DEBUG:\n",
    "        print(\"Starting checking of algorithms with root value {}\".format(root_comp))\n",
    "    result = check_alg(alg, 0, words_with_max_suffix, comps)\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "# TODO: describe\n",
    "def check_alg(alg, index, words, comps):\n",
    "    # Divide and Conquer\n",
    "    if not is_last_comp(index):\n",
    "        # Compute three subsets of the words and of the tree\n",
    "        i1, i2 = alg[index].obj\n",
    "        smaller_list = []\n",
    "        equal_list = []\n",
    "        bigger_list = []\n",
    "        for entry in words:\n",
    "            word = entry[0]\n",
    "            if word[i1] < word[i2]:\n",
    "                smaller_list.append(entry)\n",
    "            elif word[i1] == word[i2]:\n",
    "                equal_list.append(entry)\n",
    "            else:\n",
    "                bigger_list.append(entry)\n",
    "\n",
    "        current_comp = alg[index].obj\n",
    "\n",
    "        if index == 0:\n",
    "            # this is only executed once - use this place to start a thread that regularly saves checkpoints\n",
    "            still_running = threading.Event()  # signs when Interrupt was made\n",
    "            still_running.set()\n",
    "            save_thread = threading.Thread(target=save_current_graph, args=(alg[0], 60, still_running))\n",
    "            try:\n",
    "                save_thread.start()\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                # Cleanup on interrupt\n",
    "                still_running.clear()\n",
    "                save_thread.join()\n",
    "\n",
    "            # remove the comparison value at the current node from further consideration\n",
    "            comps_new_smaller = copy.deepcopy(comps)\n",
    "            comps_new_equal = copy.deepcopy(comps)\n",
    "            comps_new_bigger = copy.deepcopy(comps)\n",
    "            comps_new_smaller.remove(current_comp)\n",
    "            comps_new_equal.remove(current_comp)\n",
    "            comps_new_bigger.remove(current_comp)\n",
    "            # Note: We do not want to manipulate the root - different values will be checked in other executions\n",
    "            if (check_alg(alg, index * 3 + 1, smaller_list, comps_new_smaller) and\n",
    "                    check_alg(alg, index * 3 + 2, equal_list, comps_new_equal) and\n",
    "                    check_alg(alg, index * 3 + 3, bigger_list, comps_new_bigger)):\n",
    "                # Cleanup on finishing\n",
    "                still_running.clear()\n",
    "                save_thread.join()\n",
    "                return alg\n",
    "        else:\n",
    "            # not at root - here we want to check all possible values for the node, so we loop over comps\n",
    "            for c_new in comps:\n",
    "                if DEBUG and (not ONLY_HIGHEST_DEBUG or index < 4):\n",
    "                    print(\"[Increasing] Increasing index {} from {} to {}\".format(index, alg[index].obj, c_new))\n",
    "\n",
    "                alg[index].obj = c_new\n",
    "\n",
    "                # Compute all comparisons that can be transitively deduced for each possible outcome\n",
    "                transitive_smaller = compute_transitive_dependencies(prev_comps, (c_new, '<'))\n",
    "                transitive_equal = compute_transitive_dependencies(prev_comps, (c_new, '='))\n",
    "                transitive_bigger = compute_transitive_dependencies(prev_comps, (c_new, '>'))\n",
    "\n",
    "                comps_smaller_new = copy.deepcopy(comps)\n",
    "                # for comp in transitive_smaller:\n",
    "                #     comps_smaller_new.remove(comp)\n",
    "                #\n",
    "                comps_equal_new = copy.deepcopy(comps)\n",
    "                # for comp in transitive_equal:\n",
    "                #     comps_equal_new.remove(comp)\n",
    "                #\n",
    "                comps_bigger_new = copy.deepcopy(comps)\n",
    "                # for comp in transitive_bigger:\n",
    "                #     comps_bigger_new.remove(comp)\n",
    "\n",
    "                # remove the comparison value at the current node from further consideration\n",
    "                comps_new_smaller = copy.deepcopy(comps)\n",
    "                comps_new_equal = copy.deepcopy(comps)\n",
    "                comps_new_bigger = copy.deepcopy(comps)\n",
    "                comps_new_smaller.remove(c_new)\n",
    "                comps_new_equal.remove(c_new)\n",
    "                comps_new_bigger.remove(c_new)\n",
    "\n",
    "                # todo update prev_comps\n",
    "                if (check_alg(alg, index * 3 + 1, smaller_list, comps_new_smaller) and\n",
    "                        check_alg(alg, index * 3 + 2, equal_list, comps_new_equal) and\n",
    "                        check_alg(alg, index * 3 + 3, bigger_list, comps_new_bigger)):\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "    else:\n",
    "        for c_new in comps:\n",
    "            result_map = {}\n",
    "\n",
    "            alg[index].obj = c_new\n",
    "\n",
    "            for word, r in words:\n",
    "                result = compute_path_for_word(alg, word)\n",
    "\n",
    "                stringed_result = str(result)\n",
    "                stringed_path = \"\"\n",
    "                for node_id in result:\n",
    "                    stringed_path += str(node_id)\n",
    "                    if node_id != result[-1]:\n",
    "                        stringed_path += \" [{}]\".format(alg[node_id].obj)\n",
    "                        stringed_path += \" -> \"\n",
    "                if stringed_result in result_map and result_map[stringed_result][1] != r:\n",
    "                    break\n",
    "\n",
    "                elif word == words[-1][0]:\n",
    "                    return True\n",
    "\n",
    "                else:\n",
    "                    result_map[stringed_result] = (word, r)\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to find Algorithm for 541 interesting words\n",
      "Starting checking of algorithms with root value (0, 1)\n",
      "[Increasing] Increasing index 1 from (0, 2) to (0, 2)\n",
      "Starting checking of algorithms with root value (0, 2)\n",
      "[Increasing] Increasing index 1 from (0, 1) to (0, 1)\n",
      "Starting checking of algorithms with root value (0, 3)\n",
      "[Increasing] Increasing index 1 from (0, 1) to (0, 1)\n",
      "Starting checking of algorithms with root value (0, 4)\n",
      "[Increasing] Increasing index 1 from (0, 1) to (0, 1)\n",
      "Starting checking of algorithms with root value (1, 2)\n",
      "[Increasing] Increasing index 1 from (0, 1) to (0, 1)\n",
      "Starting checking of algorithms with root value (1, 3)\n",
      "[Increasing] Increasing index 1 from (0, 1) to (0, 1)\n",
      "Starting checking of algorithms with root value (1, 4)\n",
      "[Increasing] Increasing index 1 from (0, 1) to (0, 1)\n",
      "Starting checking of algorithms with root value (2, 3)\n",
      "[Increasing] Increasing index 1 from (0, 1) to (0, 1)\n",
      "Starting checking of algorithms with root value (2, 4)\n",
      "[Increasing] Increasing index 1 from (0, 1) to (0, 1)\n",
      "Starting checking of algorithms with root value (3, 4)\n",
      "[Increasing] Increasing index 1 from (0, 1) to (0, 1)\n",
      "finally: attempting to close pool\n",
      "pool successfully closed\n",
      "Runtime: 0.10s\n",
      "No possible algorithm exists for finding the max. suffix with N=5, M=5\n"
     ]
    }
   ],
   "source": [
    "#Helping function that stop the workers early when a solution was found\n",
    "working_alg = []\n",
    "def check_result(return_alg):\n",
    "    global working_alg\n",
    "    if not working_alg and return_alg is not None:\n",
    "        working_alg = return_alg\n",
    "        workers.terminate()\n",
    "\n",
    "words_with_max_suffix = generate_all_word_with_max_suffix()\n",
    "print(\"Need to find Algorithm for {} interesting words\".format(len(words_with_max_suffix)))\n",
    "\n",
    "#worker pool - each worker is responsible for a single root value\n",
    "workers = Pool(processes=NR_WORKERS)\n",
    "        \n",
    "start = timeit.default_timer() # measure running time\n",
    "\n",
    "try:\n",
    "    results = []\n",
    "    for comp in comp_pairs:\n",
    "        r = workers.apply_async(check_alg_for_root_comp, (comp, words_with_max_suffix, comp_pairs), callback=check_result)\n",
    "        results.append(r)\n",
    "    for r in results:\n",
    "        r.wait()\n",
    "except (KeyboardInterrupt , SystemExit):\n",
    "    workers.terminate()\n",
    "finally:\n",
    "    print(\"finally: attempting to close pool\")\n",
    "    workers.terminate()\n",
    "    print(\"pool successfully closed\")\n",
    "    \n",
    "print(\"Runtime: {:.2f}s\".format(timeit.default_timer() - start))\n",
    "if working_alg:\n",
    "    print(\"Algorithm probably succeded\")\n",
    "    #Verify (fill in correct r-values in tree on the way in order to pretty print it)\n",
    "    result_map = {}\n",
    "    for word, r in words_with_max_suffix:\n",
    "        result = compute_path_for_word(alg, word)\n",
    "        alg[result[-1]].obj = r\n",
    "\n",
    "        stringed_result = str(result)\n",
    "        stringed_path = \"\"\n",
    "        for node_id in result:\n",
    "            stringed_path += str(node_id)\n",
    "            if node_id != result[-1]:\n",
    "                stringed_path += \" [{}]\".format((alg[node_id].obj))\n",
    "                stringed_path += \" -> \"\n",
    "        if stringed_result in result_map and result_map[stringed_result][1] != r:\n",
    "            #Found witness path\n",
    "            print(\"Not verified!\")\n",
    "            break\n",
    "                \n",
    "        elif word == words_with_max_suffix[-1][0]:\n",
    "            print(\"Verified\")\n",
    "            print(\"Algorithm SUCCEEDED\")\n",
    "            \n",
    "            filled_leafs = 0\n",
    "            for i, node in enumerate(alg):\n",
    "                if is_leaf(i) and node.obj != \"\":\n",
    "                    filled_leafs += 1\n",
    "            print(\"Filled leafs: {}/{}\".format(filled_leafs, 3**M))\n",
    "            print(\"Tree Structure: \")\n",
    "            for pre, fill, node in RenderTree(alg[0]):\n",
    "                print(\"%s%s\" % (pre, node.obj))\n",
    "            ts = str(datetime.datetime.now().timestamp() * 1000)\n",
    "            DotExporter(alg[0], nodeattrfunc=lambda node: 'label=\"{}\"'.format(node.obj)).to_picture(\"{}/{}.png\".format(dir, ts))\n",
    "            DotExporter(alg[0], nodeattrfunc=lambda node: 'label=\"{}\"'.format(node.obj)).to_dotfile(\"{}/{}.txt\".format(dir, ts))\n",
    "\n",
    "        result_map[stringed_result] = (word, r)\n",
    "        \n",
    "else:\n",
    "    print(\"No possible algorithm exists for finding the max. suffix with N={}, M={}\".format(N,M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
